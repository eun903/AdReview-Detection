from typing import Optional
from fastapi import FastAPI
from pydantic import BaseModel
import mysql.connector
import json
import numpy as np
from sentence_transformers import SentenceTransformer
import logging
from sklearn.metrics.pairwise import cosine_similarity
import re
import os
from dotenv import load_dotenv

import google.generativeai as genai  # Google Gemini API
from fastapi.middleware.cors import CORSMiddleware

# ============================================
# í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
# ============================================

app = FastAPI(title="Ad Review Analyzer API")
logging.basicConfig(level=logging.INFO)

load_dotenv()

# Google Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ ì¤‘ì—” * í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================
# 1. íŒŒì¸íŠœë‹ëœ MiniLM ëª¨ë¸ ë¡œë“œ
# ============================================
logging.info("ğŸš€ Loading fine-tuned MiniLM model...")
model = SentenceTransformer("./finetuned_minilm_model")

# ============================================
# 2. DB ì„¤ì •
# ============================================
DB_CONFIG = {
    "host": "localhost",
    "database": "review_similarity",
    "user": "root",
    "password": "onlyroot",
    "auth_plugin": "mysql_native_password",
    "charset": "utf8mb4"
}

# ============================================
# 3. í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ë¡œë“œ
# ============================================
with open("keyword_weights.json", "r", encoding="utf-8") as f:
    KEYWORD_WEIGHTS = json.load(f)

AD_WEIGHTS = KEYWORD_WEIGHTS.get("AD_WEIGHTS", {})
NON_AD_WEIGHTS = KEYWORD_WEIGHTS.get("NON_AD_WEIGHTS", {})

# ============================================
# 4. DB ì—°ê²° í•¨ìˆ˜
# ============================================
def get_db_connection():
    return mysql.connector.connect(**DB_CONFIG)

# ============================================
# 5. ìš”ì²­/ì‘ë‹µ ëª¨ë¸
# ============================================
class ReviewRequest(BaseModel):
    review: Optional[str] = None
    userReview: Optional[str] = None
    category: Optional[str] = None

class ReviewResponse(BaseModel):
    ì…ë ¥_ë¦¬ë·°: str
    ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°: str
    ìœ ì‚¬ë„_ì ìˆ˜: float
    label: int
    í›„ë³´_ë¦¬ë·°ë“¤: list
    íŒë‹¨: str
    ê´‘ê³ _í‚¤ì›Œë“œ: list
    ë¹„ê´‘ê³ _í‚¤ì›Œë“œ: list
    ìš”ì•½ë¬¸: str

# ============================================
# 6. í‚¤ì›Œë“œ ë§¤ì¹­ í•¨ìˆ˜
# ============================================
def match_keywords(text: str, keyword_list: list) -> list:
    results = []
    for kw in keyword_list:
        pattern = re.escape(kw)
        if re.search(pattern, text, re.I):
            results.append(kw)
    return results

# ============================================
# 7. ë¦¬ë·° ìœ íš¨ì„± ê²€ì‚¬
# ============================================
def is_valid_review(text: str) -> bool:
    if text is None:
        return False
    text = text.strip()
    if len(text) < 5 or text.isdigit():
        return False
    if all(ch in "!@#$%^&*()_+=-[]{};:'\",.<>?/|" for ch in text):
        return False
    return True

# ============================================
# 8. ì•ˆì „í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
# ============================================
def safe_cosine_similarity(vec1, vec2):
    denom = (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    if denom == 0:
        return 0.0
    return float(np.dot(vec1, vec2) / denom)

# ============================================
# 9. ë¦¬ë·° ìš”ì•½ í•¨ìˆ˜ (Google Gemini)
# ============================================
def summarize_text(text: str) -> str:
    try:
        if not text.strip():
            return ""
        prompt = f"ë‹¤ìŒ ë¦¬ë·°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜. ëì€ '~ë‹¤'ë¡œ ë§ˆë¬´ë¦¬í•´ì¤˜:\n\n{text}"
        model_gemini = genai.GenerativeModel("gemini-2.0-flash")
        response = model_gemini.generate_content(prompt)
        return response.text.strip() if response and response.text else "(ìš”ì•½ ì‹¤íŒ¨)"
    except Exception as e:
        print("âŒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜:", e)
        return "(ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ)"

# ============================================
# 10. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜
# ============================================
# ============================================
# 10. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ (ë””ë²„ê·¸ ë¡œê¹… ì¶”ê°€ ë²„ì „)
# ============================================
def analyze_review(user_review: str, category: Optional[str] = None, top_n=3):
    # í‚¤ì›Œë“œ ë§¤ì¹­
    matched_ad_keywords = match_keywords(user_review, AD_WEIGHTS.keys())
    matched_non_ad_keywords = match_keywords(user_review, NON_AD_WEIGHTS.keys())

    # ë¦¬ë·° ê²€ì¦
    if not is_valid_review(user_review):
        return {
            "ì…ë ¥_ë¦¬ë·°": user_review or "",
            "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": "",
            "ìœ ì‚¬ë„_ì ìˆ˜": 0.0,
            "label": -1,
            "í›„ë³´_ë¦¬ë·°ë“¤": [],
            "íŒë‹¨": "ë¶„ì„ ë¶ˆê°€ (ë¦¬ë·° ë‚´ìš© ë¶€ì¡±)",
            "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
            "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords,
            "ìš”ì•½ë¬¸": ""
        }

    # 1. ë²¡í„°í™”
    user_vec = model.encode(user_review)
    
    # ğŸ”´ ë””ë²„ê·¸: ì‚¬ìš©ì ë²¡í„° ìƒíƒœ í™•ì¸
    vector_norm = np.linalg.norm(user_vec)
    logging.info(f"DEBUG: User Vector Dimension: {len(user_vec)}")
    logging.info(f"DEBUG: User Vector Norm (ê¸¸ì´): {vector_norm:.4f}")
    if vector_norm < 0.1: # 0ì— ê°€ê¹Œìš´ì§€ í™•ì¸ (MiniLM-L6-v2ëŠ” ë³´í†µ 4~6 ì‚¬ì´ì˜ ê¸¸ì´ë¥¼ ê°€ì§)
         logging.warning("âš ï¸ WARNING: User vector norm is very low. Possible encoding failure or zero vector.")
    # -------------------------------------------------------------

    # DB ì¡°íšŒ
    conn = get_db_connection()
    cur = conn.cursor(dictionary=True)
    if category:
        cur.execute("""
            SELECT cleaned_review, label, review_vector, category
            FROM reviews
            WHERE review_vector IS NOT NULL
            AND review_vector != ''
            AND TRIM(category) = %s
            AND label = 1
        """, (category,))
    else:
        cur.execute("""
            SELECT cleaned_review, label, review_vector, category
            FROM reviews
            WHERE review_vector IS NOT NULL
            AND review_vector != ''
            AND label = 1
        """)
    rows = cur.fetchall()
    cur.close()
    conn.close()

    if not rows:
        return {
            "ì…ë ¥_ë¦¬ë·°": user_review,
            "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": "",
            "ìœ ì‚¬ë„_ì ìˆ˜": 0.0,
            "label": -1,
            "í›„ë³´_ë¦¬ë·°ë“¤": [],
            "íŒë‹¨": "ë°ì´í„° ë¶€ì¡± (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì—†ìŒ)",
            "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
            "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords,
            "ìš”ì•½ë¬¸": ""
        }

    # 2. ìœ ì‚¬ë„ ê³„ì‚°
    candidates = []
    best_score = -1.0
    best_review = ""
    best_label = -1
    for row in rows:
        try:
            review_vec = np.array(json.loads(row["review_vector"]))
            score = safe_cosine_similarity(user_vec, review_vec)
            candidates.append({"review": row["cleaned_review"], "score": float(score), "label": row["label"]})
            if score > best_score:
                best_score = score
                best_review = row["cleaned_review"]
                best_label = row["label"]
        except Exception as e:
            logging.warning(f"âš ï¸ ë²¡í„° íŒŒì‹± ì—ëŸ¬: {e}")
            continue

    # ğŸ”´ ë””ë²„ê·¸: ë³´ì • ì „ ìˆœìˆ˜í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸
    logging.info(f"DEBUG: Pure Max Cosine Similarity (Before Adjustment): {best_score * 100:.2f}%")
    # -----------------------------------------------------------------------

    candidates.sort(key=lambda x: x["score"], reverse=True)
    top_candidates = candidates[:top_n]

    # 3. í‚¤ì›Œë“œ ë³´ì • (JSON ê°€ì¤‘ì¹˜ ì ìš©)
    keyword_adjustment = sum([AD_WEIGHTS.get(k, 0) for k in matched_ad_keywords]) \
                         + sum([NON_AD_WEIGHTS.get(k, 0) for k in matched_non_ad_keywords])
    
    # ğŸ”´ ë””ë²„ê·¸: í‚¤ì›Œë“œ ì¡°ì •ì¹˜ í™•ì¸
    logging.info(f"DEBUG: Keyword Adjustment Value: {keyword_adjustment:.4f}")
    # -------------------------------------------------------------

    final_score = max(0, min(1, best_score + keyword_adjustment))
    score_percent = round(final_score * 100, 2)
    
    # ğŸ”´ ë””ë²„ê·¸: ìµœì¢… ë³´ì • ì ìˆ˜ í™•ì¸
    logging.info(f"DEBUG: Final Score (After Adjustment): {score_percent:.2f}%")
    # -------------------------------------------------------------

    # íŒë‹¨
    if score_percent >= 85:
        decision_text = "ê´‘ê³ ì„± ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ë†’ìŒ"
        best_label = 1
    elif 70 <= score_percent < 85:
        decision_text = "ê´‘ê³ ì„± ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ìˆìŒ"
        best_label = 1
    elif 40 <= score_percent < 70:
        decision_text = "ì¼ë°˜ ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ìˆìŒ"
        best_label = 0
    else:
        decision_text = "ì¼ë°˜ ë¦¬ë·°ì¼ ê°€ëŠ¥ì„± ë†’ìŒ"
        best_label = 0

    # ìš”ì•½ë¬¸
    summary = summarize_text(user_review)

    # ê²°ê³¼ ë°˜í™˜
    return {
        "ì…ë ¥_ë¦¬ë·°": user_review,
        "ê°€ì¥_ìœ ì‚¬í•œ_ê´‘ê³ _ë¦¬ë·°": best_review,
        "ìœ ì‚¬ë„_ì ìˆ˜": score_percent,
        "label": int(best_label),
        "í›„ë³´_ë¦¬ë·°ë“¤": [{"review": c["review"], "score": round(c["score"] * 100, 2)} for c in top_candidates],
        "íŒë‹¨": decision_text,
        "ê´‘ê³ _í‚¤ì›Œë“œ": matched_ad_keywords,
        "ë¹„ê´‘ê³ _í‚¤ì›Œë“œ": matched_non_ad_keywords,
        "ìš”ì•½ë¬¸": summary
    }
# ============================================
# FastAPI ë¼ìš°íŠ¸
# ============================================
@app.get("/")
def root():
    return {"message": "FastAPI ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘ ğŸš€"}

@app.post("/analyze", response_model=ReviewResponse)
def analyze(data: ReviewRequest):
    text = (data.review or data.userReview or "").strip()
    category = data.category
    logging.info(f"ğŸ“¦ ë°›ì€ category ê°’: {category}")
    return analyze_review(text, category)
